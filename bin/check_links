#!/usr/bin/env ruby
# check_links -- ODDB -- 27.11.2003 -- hwyss@ywesee.com

$: << File.expand_path('../src', File.dirname(__FILE__))

require 'util/html_parser'
require 'net/http'
require 'util/oddbconfig'
require 'util/oddbapp'
begin
	require 'testenvironment'
	puts "loaded testenvironment"
rescue LoadError
end

num_threads = 1
flavor = 'gcc'
$respect_session = false
while(arg = ARGV.shift)
	case arg
	when 'session'
		$respect_session = true
	when
		/\d+/
		num_threads = [arg.to_i, num_threads].max
	when /[a-z]{3,}/
		flavor = arg
	end
end

module ODDB
	class CrawlerWriter < NullWriter
		def initialize
			@links = []
		end
		def new_linkhandler(handler)
			if(handler && (href = handler.attribute("href")))
				#printf("href: %s\n", href.inspect)
				@links.push(href) 
			end
		end
		def send_meta(attrs)
			if(attrs.any? { |key, val| /http-equiv/i.match(key) \
				&& /refresh/i.match(val)} )
				@error_flag = true
			end
		end
		def links
			@links unless @error_flag
		end
	end
	class Crawler
		def initialize(id, flavor)
			@id = id
			@links = [ "/de/#{flavor}" ]
			@visited = []
			@errors = []
			@session = Net::HTTP.new(SERVER_NAME)
			@cookies = {}
			@state_id_regexp = Regexp.new('state_id/[0-9\-]+/')
			@load_max = nil
			@load_max_url = nil
			@load_min = nil
			@load_min_url = nil
		end
		def check_links
			@links.each_with_index { |link, idx|
				printf("Session: %3d - requested: %8d: %s\n", @id, idx, link)
				@visited.push(link)
				start = Time.now
				if(html = get_http(link))
					time = Time.now - start
					if(@load_max.nil? || @load_max < time)
						@load_max = time
						@load_max_url = link
					end
					if(@load_min.nil? || @load_min > time)
						@load_min = time
						@load_min_url = link
					end
					printf("Session: %3d - received:  %8d: %s in %1.2fs\n", @id, idx, link, time)
					if(links = extract_links(html))
						schedule_links(links, idx)
					end
				else
					printf("Session: %3d - ## error:  %8d: %s in %1.2fs\n", @id, idx, link, Time.now - start)
					@errors.push(link)
				end
			}
		end
		def report
			puts "# Session #{@id} ####################################"
			puts "Visited #{@visited.size} links."
			puts "Encountered #{@errors.size} errors:"
			puts @errors
			puts "Shortest Load-Time: #@load_min s (#@load_min_url)"
			puts "Longest  Load-Time: #@load_max s (#@load_max_url)"
		end
		def schedule_links(links, idx)
=begin
			puts "scheduling...."
			puts links
			puts "-"*40
			puts @visited
			puts "="*40
			puts links-@visited
			puts "*"*40
=end
			links.each { |link|
				if((link.index(SERVER_NAME) || link[0] == ?/)\
					&& !link.index('download') \
					&& !@links.include?(link))
					if(link.index('state_id'))
						@links[idx.next, 0] = link
					else
						@links[rand(@links.size), 0] = link
					end
				end
			}
		end
		def extract_links(html)
			writer = CrawlerWriter.new
			formatter = HtmlFormatter.new(writer)
			parser = HtmlParser.new(formatter)
			parser.feed(html)
			if(links = writer.links)
				links.compact.collect { |link| 
					link.gsub(@state_id_regexp, '')
				}
			end
		end
		def get_http(link)
			try = 3
			begin
				continuation = nil
				callcc { |continuation| }	
				resp = @session.get(link, headers)
				if resp.is_a? Net::HTTPOK
					if(rand(100) < 30)
						#impatient 30% that click again
						continuation.call
					end
					update_cookies(resp) if($respect_session)
					resp.body
				end
			rescue Timeout::Error, EOFError
				if(try > 0)
					sleep 10
					try -= 1
					retry
				end
			rescue StandardError => e
				puts e.message
			end
		end
		def update_cookies(resp)
			if(cookiestring = resp['set-cookie'])
				ptrn = /(?:^|, (?!\d))([^;]+)/
				cookiestring.scan(ptrn) { |cookie|
					@cookies.store(*(cookie[0].split('=',2)))
				}
			end
		end
		def cookies
			@cookies.collect { |var| var.join('=') }.join('; ')
		end
		def headers
			{
				'Cookie'          =>  cookies,
				#'User-Agent'      =>  'Oddb Test-Crawler',
				'User-Agent'			=>	'Mozilla',
			}
		end
	end
end

#trap('INT') { exit }

puts "checking links for #{ODDB::SERVER_NAME}"
puts "flavor:      #{flavor}"
puts "sessions:    #{$respect_session}"
puts "concurrent:  #{num_threads}"
crawlers = []
threads = []
num_threads.times { |num|
	threads.push Thread.new {
		crawler = ODDB::Crawler.new(num, flavor)
		crawlers.push(crawler)
		crawler.check_links
	}
}

at_exit {
	crawlers.each { |crawler| crawler.report } 
}

threads.each { |thread|
	thread.join
}
